<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>lain - about</title><link href="/" rel="alternate"></link><link href="/feeds/about.atom.xml" rel="self"></link><id>/</id><updated>2023-03-31T00:00:00+09:00</updated><entry><title>About Me</title><link href="/about.html" rel="alternate"></link><published>2022-06-19T00:00:00+09:00</published><updated>2023-03-31T00:00:00+09:00</updated><author><name>lento</name></author><id>tag:None,2022-06-19:/about.html</id><summary type="html">&lt;h2&gt;Personal Information&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Name: So Hasegawa&lt;/li&gt;
&lt;li&gt;Age: 29&lt;/li&gt;
&lt;li&gt;Mail: crosssceneofwindff |at| gmail |dot| com&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Publications and Conferences&lt;/h2&gt;
&lt;h3&gt;Peer reviewed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://openreview.net/forum?id=OJ8aSjCaMNK"&gt;Multi-Rate VAE: Train Once, Get the Full Rate-Distortion Curve&lt;/a&gt;&lt;br&gt;
  J. Bae, M. R. Zhang, M. Ruan, E. Wang, &lt;strong&gt;S. Hasegawa&lt;/strong&gt;, J. Ba, R. Grosse&lt;br&gt;
  In International Conference on Learning Representations (ICLR), 2023 …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;h2&gt;Personal Information&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Name: So Hasegawa&lt;/li&gt;
&lt;li&gt;Age: 29&lt;/li&gt;
&lt;li&gt;Mail: crosssceneofwindff |at| gmail |dot| com&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Publications and Conferences&lt;/h2&gt;
&lt;h3&gt;Peer reviewed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://openreview.net/forum?id=OJ8aSjCaMNK"&gt;Multi-Rate VAE: Train Once, Get the Full Rate-Distortion Curve&lt;/a&gt;&lt;br&gt;
  J. Bae, M. R. Zhang, M. Ruan, E. Wang, &lt;strong&gt;S. Hasegawa&lt;/strong&gt;, J. Ba, R. Grosse&lt;br&gt;
  In International Conference on Learning Representations (ICLR), 2023&lt;/li&gt;
&lt;li&gt;&lt;a href="https://openaccess.thecvf.com/content/WACV2023/html/Hasegawa_Improving_Predicate_Representation_in_Scene_Graph_Generation_by_Self-Supervised_Learning_WACV_2023_paper.html"&gt;Improving Predicate Representation in Scene Graph Generation by Self-Supervised Learning&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;S. Hasegawa&lt;/strong&gt;, M. Hiromoto, A. Nakagawa, Y. Umeda&lt;br&gt;
  In IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2023&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Non-peer reviewed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://onepetro.org/SPEADIP/proceedings-abstract/20ADIP/3-20ADIP/D031S080R004/452202"&gt;Facilitating the Identification of the Nannofossil Species in Cretaceous of Abu Dhabi Using Artificial Intelligence&lt;/a&gt;&lt;br&gt;
  H. Tamamura, M. Yamanaka, S. Chiyonobu, G. Yamada, &lt;strong&gt;S. Hasegawa&lt;/strong&gt;, Y. Totake, T. Nanjo&lt;br&gt;
  In Abu Dhabi International Petroleum Exhibition &amp;amp; Conference, 2020&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.jstage.jst.go.jp/article/jsapmeeting/2017.2/0/2017.2_848/_article/-char/ja/"&gt;Analysis of light absorption characteristics in very-thin single-crystalline silicon solar cells with photonic crystals&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;S. Hasegawa&lt;/strong&gt;, K. Ishizaki, Y. Tanaka, and S. Noda&lt;br&gt;
  In 78th Japan Society of Applied Physics (JSAP) Autumn Meeting, 2017&lt;/li&gt;
&lt;li&gt;&lt;a href="https://confit.atlas.jp/guide/event/jsap2016s/subject/22a-S621-3/advanced"&gt;Numerical analysis of μc-Si solar cells with photonic crystals formed on top surface -Introduction of asymmetric structure-&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;S. Hasegawa&lt;/strong&gt;, K. Ishizaki, Y. Tanaka, A. Motohira, Y. Kawamoto, M. De Zoysa, S. Fujita, and S. Noda&lt;br&gt;
  In 63th Japan Society of Applied Physics (JSAP) Spring Meeting, 2016&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Invited Lectures and Talks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.slideshare.net/SouHasegawa/generative-adversarial-networks-186237021"&gt;Generative Adversarial Networksの基礎と応用について (Basics and Applications of Generative Adversarial Network)&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;S. Hasegawa&lt;/strong&gt;&lt;br&gt;
  Invited lecture at Tohoku University, 2019&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.slideshare.net/SouHasegawa/ss-189697036"&gt;データに寄りそう着色の作法 (Basics of Line Art Colorization)&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;S. Hasegawa&lt;/strong&gt;&lt;br&gt;
  Talk at &lt;a href="https://connpass.com/event/149734/"&gt;創作＋機械学習LT会&lt;/a&gt;, 2019&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Education&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Apr 2016 ~ Mar 2018: MEng in Electronics at Kyoto University&lt;ul&gt;
&lt;li&gt;Thesis: Fabrication and Evaluation of Thin Single-Crystalline Silicon Solar Cells with Photonic Crystals&lt;/li&gt;
&lt;li&gt;Supervisor: Susumu Noda&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Apr 2012 ~ Mar 2016: BEng in Electrical and Electronic Engineering at Kyoto University&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Work Experience&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Oct 2022 ~ : machine learning researcher at Fujitsu Research of America&lt;ul&gt;
&lt;li&gt;My research is focused on AutoML&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Aug 2021 ~ Sep 2022: machine learning researcher at Fujitsu Research&lt;ul&gt;
&lt;li&gt;My research was focused on scene graph generation, self-supervised learning, and generative models&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sep 2019 - Jan 2020: research assistant at SYMBOL&lt;ul&gt;
&lt;li&gt;My work was focused on developing deep learning-based solutions to extract essential information from 3D data (point cloud, mesh, multi-view)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Apr 2018 ~ Jul 2021: software engineer at Fujitsu&lt;ul&gt;
&lt;li&gt;My work was focused on providing deep learning-based solutions with the customers and developing software products using speech processing and computer vision technologies&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Personal Projects&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Project name&lt;/th&gt;
&lt;th&gt;Descrption&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/SerialLain3170/adeleine"&gt;adeleine&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep learning-based implementations of line art colorization with hints and without hints. Userhintv2 model in the repository is used in &lt;a href="https://experiments.withgoogle.com/giga-manga"&gt;Giga Manga&lt;/a&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/SerialLain3170/senju"&gt;senju&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Several deep-learning based implementations pertaining to anime. The repository also includes GUI application consisting of Go server and Python modules connected via gRPC.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/SerialLain3170/accela"&gt;accela&lt;/a&gt; and &lt;a href="https://github.com/SerialLain3170/cyberia"&gt;cyberia&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Music digging tools. accela is implemented in TypeScript, and cyberia is done in Python.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/SerialLain3170/AwesomeAnimeResearch"&gt;AwesomeAnimeResearch&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A massive collection of machine learning papers and projects related to anime&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;Skills&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Computer Science&lt;ul&gt;
&lt;li&gt;Machine Learning, Deep learning&lt;/li&gt;
&lt;li&gt;Signal Processing: Computer vision, Speech processing&lt;/li&gt;
&lt;li&gt;Low-level Programming: Emulators of NES, GB, CGB&lt;/li&gt;
&lt;li&gt;Programming Language: Python, Go, C&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Software Development&lt;ul&gt;
&lt;li&gt;Team development&lt;/li&gt;
&lt;li&gt;OS: Linux(Ubuntu, CentOS), MacOS, Windows&lt;/li&gt;
&lt;li&gt;Tools: Docker, Docker-compose, Git, Gitlab, Github, MySQL, PostgreSQL, MongoDB, Nodejs, gRPC, Nginx, RabbitMQ&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Language&lt;ul&gt;
&lt;li&gt;Japanese: native&lt;/li&gt;
&lt;li&gt;English: advanced (TOEFL: 96, IELTS: 7.0, GRE: V153/Q170/AW3.5)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Interests&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Programming (visit &lt;a href="https://github.com/SerialLain3170"&gt;Github&lt;/a&gt; and &lt;a href="https://medium.com/@crosssceneofwindff"&gt;Medium&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Visual arts: watching all kinds of arts, visiting art museums, and learning art history&lt;/li&gt;
&lt;li&gt;Books: science (computer science, biology, geology), art, history, finance (visit &lt;a href="https://bookmeter.com/users/1378090"&gt;Bookmeter&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Music: listening, playing the piano, composing (visit &lt;a href="https://soundcloud.com/lento-3"&gt;Soundcloud&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Travel and enjoy nature (visit &lt;a href="https://www.flickr.com/photos/197623303@N08/"&gt;flickr&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;</content><category term="about"></category><category term="about"></category></entry></feed>