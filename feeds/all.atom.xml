<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>lain</title><link href="/" rel="alternate"></link><link href="/feeds/all.atom.xml" rel="self"></link><id>/</id><updated>2024-01-22T00:00:00+09:00</updated><entry><title>Henri Matisse "Woman with a hat"</title><link href="/3-woman_with_a_hat.html" rel="alternate"></link><published>2024-01-22T00:00:00+09:00</published><updated>2024-01-22T00:00:00+09:00</updated><author><name>lento</name></author><id>tag:None,2024-01-22:/3-woman_with_a_hat.html</id><summary type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;At the end of 2023, I visited &lt;a href="https://www.sfmoma.org/"&gt;San Francisco Museum of Modern Art (SFMOFA)&lt;/a&gt; in San Francisco. I encountered elementary school students who finished having a school field trip at SFMOMA when I just entered the museum, then I went to the second stair while imagining what the students …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;At the end of 2023, I visited &lt;a href="https://www.sfmoma.org/"&gt;San Francisco Museum of Modern Art (SFMOFA)&lt;/a&gt; in San Francisco. I encountered elementary school students who finished having a school field trip at SFMOMA when I just entered the museum, then I went to the second stair while imagining what the students saw and thought. The goal of my visit was to watch "Woman with a hat" by Henri Matisse, which is one of SFMOMA collection. I was excited to watch the paining that locates near various modern paintings SFMOMA has.&lt;/p&gt;
&lt;h2&gt;Exhibition at Tokyo Metropolitan Art Museum&lt;/h2&gt;
&lt;p&gt;In the first place, the impetus to watch the painting went back to May 2023. I went to Tokyo Metropolitan Art Museum to see &lt;a href="https://www.tobikan.jp/en/exhibition/2023_matisse.html"&gt;the special exhibition featuring Matisse&lt;/a&gt; while during the trip to Japan. I was totally intrigued by the exhibition due to two reasons. First reason is that there will be few opportunities to see Matisse's a lot of paintings at the same time during my life. In fact, there was about 150 paintings from Centre Pompidou at Paris. Second, I personally had been longing for seeing &lt;a href="https://en.wikipedia.org/wiki/Luxe,_Calme_et_Volupt%C3%A9"&gt;"Luxe, Calme et Volupté"&lt;/a&gt; due to the audacious distribution of colors, and the painting came to the exhibition.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Title of the exhibition" src="/images/2_path_to_the_color.jpg"&gt;&lt;/p&gt;
&lt;p&gt;It was a meaningful exhibition to see an overview of Matisse's life as an artist ranging from realistic paintings in his early stage to the chapel in his last days. Matisse is basically regarded as a key artist of Fauvism or a magician of colors, so a lot of people tend to focus on the usage of colors. However, I have felt that he would focus on not only colors but also shapes according to the exhibition. For example, let's take a look at "The Back Ⅰ-Ⅳ" that represents back of a woman. There was a trajectory of an abstraction from the woman's back with clear lines to one with only vertical lines, implying that he would explore a rebellion of the shape. Based on my perspective, Matisse might have kept himself asking, "what is the minimum composition of the object in terms of colors and shapes?", and the goal would lead to keeping an eye on cutout pictures and chapels because the compositions of them are very simple (Of course, the interest in cutout pictures was mainly related to his physical challenges). As a machine learning researcher, my research theme is representation learning, and I am really interested in the minimum composition of objects. The closeness between my interest and his interest made me a little glad.&lt;/p&gt;
&lt;p&gt;Anyway, there seemed to be few paintings in the days of Fauvism at the exhibition. I understand that Fauvism does not represent all of himself and that the days were only one portion of his long life as an artist. Hence, this observation was just based on my preference. I have not investigated where to see his famous paintings of the Fauvism days, "Woman with a hat" and &lt;a href="https://en.wikipedia.org/wiki/The_Green_Stripe"&gt;"Portrait of Madame Matisse (The green line)"&lt;/a&gt; and found that the latter is in Statens Museum for Kunst and that the former is in SFMOMA. That is why I have decided to go to SFMOMA to watch the painting, and I am here.&lt;/p&gt;
&lt;h2&gt;Woman with a hat&lt;/h2&gt;
&lt;p&gt;&lt;img alt="Woman with a hat" src="/images/1_woman_with_a_hat.jpg"&gt;&lt;/p&gt;
&lt;p&gt;"Woman with a hat" represents a rebellion of colors. Almost all the colors here would be detached from the real colors in front of him. Even the color of the dress is totally different because his wife wore the black dress at that time according to the caption. Although I do not touch where was an origin of Fauvism in the detail because various medias have mentioned about that, seeing "Luxe, Calme et Volupté" has strengthened the idea that Pointillism would have given a hint to Fauvism. Pointillism artists put dots with complementary colors (unrealistic colors) to make the painting more vivid. Although Surat, who is the founder of Pointillism, had put millions of tiny dots following the principle, Signac or Delaunay gradually had enlarged the size of dots, and the a ratio of unrealistic colors occupied in the painting became greater. The transition would give various artists the idea, "Are there any necessities to put colors that the real object has?", leading to Fauvism. Therefore, based on the transition and the expansion of Pointillism to various artists (Delaunay, Van Gogh, and Kandinsky), not only Matisse had the possibility to start Fauvism, and many artists might have possibilities to invent Fauvism-like paintings. However, he was the only person to achieve the delicate construction of the audacious colors and beautiful appearance. Hence, "Woman with a hat" is a monumental work as the advent of Fauvism.&lt;/p&gt;</content><category term="art"></category><category term="art"></category></entry><entry><title>Links</title><link href="/2-links.html" rel="alternate"></link><published>2024-01-08T00:00:00+09:00</published><updated>2024-01-08T00:00:00+09:00</updated><author><name>lento</name></author><id>tag:None,2024-01-08:/2-links.html</id><summary type="html">&lt;h2&gt;Summary of Links&lt;/h2&gt;
&lt;p&gt;This page is an overview of all the links related to me at 01/2024 both in Japanese (ja) and in English (en). Please visit them if you are interested in and please tell me the next comfortable Twitter...&lt;/p&gt;
&lt;h3&gt;Overview&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://seriallain3170.github.io/about.html#about"&gt;Self-introduction (en)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://scrapbox.io/serialexperimentscrie/%E8%BF%91%E6%B3%81"&gt;Recent days (ja)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://scrapbox.io/serialexperimentscrie/"&gt;Self-reflection (ja …&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;h2&gt;Summary of Links&lt;/h2&gt;
&lt;p&gt;This page is an overview of all the links related to me at 01/2024 both in Japanese (ja) and in English (en). Please visit them if you are interested in and please tell me the next comfortable Twitter...&lt;/p&gt;
&lt;h3&gt;Overview&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://seriallain3170.github.io/about.html#about"&gt;Self-introduction (en)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://scrapbox.io/serialexperimentscrie/%E8%BF%91%E6%B3%81"&gt;Recent days (ja)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://scrapbox.io/serialexperimentscrie/"&gt;Self-reflection (ja)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Research and Development&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://scholar.google.com/citations?user=tzKL43UAAAAJ&amp;amp;hl=en"&gt;Google scholar&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/SerialLain3170"&gt;Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@crosssceneofwindff"&gt;Tech blog (ja)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://seriallain3170.github.io/"&gt;Tech blog (en)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;SNS&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://twitter.com/NieA7_3170"&gt;Twitter (ja)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/Crie_functional"&gt;Twitter (en)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.linkedin.com/in/so-hasegawa-5aa509169/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Hobby&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://bookmeter.com/users/1378090"&gt;Bookmeter (ja)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://soundcloud.com/lento-3"&gt;Soundcloud&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.flickr.com/photos/197623303@N08/"&gt;flickr&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="about"></category><category term="about"></category></entry><entry><title>AwesomeAnimeResearch: Past, Present, and Future</title><link href="/1-awesomeanimeresearch.html" rel="alternate"></link><published>2022-11-24T00:00:00+09:00</published><updated>2022-11-24T00:00:00+09:00</updated><author><name>lento</name></author><id>tag:None,2022-11-24:/1-awesomeanimeresearch.html</id><summary type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I have created and managed a repository, named &lt;a href="https://github.com/SerialLain3170/AwesomeAnimeResearch"&gt;AwesomeAnimeResearch&lt;/a&gt; for more than two years (the first commit was at 04/27/2020). Thanks to contributors and issue builders, we have collected more than 250 papers related to anime, illustration, and comic. I would like to explain motivation to create …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I have created and managed a repository, named &lt;a href="https://github.com/SerialLain3170/AwesomeAnimeResearch"&gt;AwesomeAnimeResearch&lt;/a&gt; for more than two years (the first commit was at 04/27/2020). Thanks to contributors and issue builders, we have collected more than 250 papers related to anime, illustration, and comic. I would like to explain motivation to create the repository, design, present challenges, and future plans.&lt;/p&gt;
&lt;h2&gt;Motivation&lt;/h2&gt;
&lt;p&gt;Until I created the repository, I used to take a look at &lt;a href="https://github.com/shubhampachori12110095/DeepLearningAnimePapers"&gt;DeepLearningAnimePapers&lt;/a&gt; to investigate papers related to anime. Since it had stopped updates in 2018, I had possessed a desire to create awesome-list for anime papers that contains a massive and exciting collection. Therefore, &lt;a href="https://twitter.com/NieA7_3170/status/1258700433356283910?s=20&amp;amp;t=PrGYp5veSVDrUamtQqjMCg"&gt;I started to manage AwesomeAnimeResearch&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Design&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;In the first place, what is the definition of "papers related to anime, illustration, and comic"? I have defined it as the published or preprint papers that explicitly include applications for these fields. For example, if the paper is about image generation and includes the generated figures of not only human faces but also anime characters, the paper clearly shows potentials for anime applications. Of course, since the definition is from all my perspectives, I am willing to discuss the appropriate definition.&lt;/li&gt;
&lt;li&gt;There are 2 categories of resources in AwesomeAnimeResearch: paper and project. Papers are the papers in accordance with the definition that I stated. Projects are not the papers but they are tech reports or github repositories that have contributed to promoting machine learning research related to anime (e.g. &lt;a href="https://make.girls.moe/#/"&gt;makegirlsmoe&lt;/a&gt; or &lt;a href="https://github.com/lllyasviel/style2paints"&gt;style2paints&lt;/a&gt;). &lt;/li&gt;
&lt;li&gt;I have set 21 categories like below based on my perspective, and four categories have their own subcategories.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;- Dataset
- Image Generation
  |- Generation
  |- Few-shot
  |- Interpretability
  |- Montage
- Image-to-Image Translation
  |- Face2anime
  |- Selfie2anime
  |- Photo2anime
  |- Sketch2anime
  |- Photo2manga
  |- Anime2costume
  |- Style transfer
  |- Author style transfer
- Automatic Line Art Colorization
  |- NoHint
  |- Atari
  |- Reference
  |- Tag
  |- Video
- Automatic Character Lighting
- Automatic Illustration Editing
- Automatic Sketch Editing
- Automatic Animation Inbetweening
- Automatic Image Enhancement
- Character Animating
- Manga Application
  |- Generation
  |- Restoration
  |- Inpainting
  |- Text detection
  |- Landmark detection
  |- Segmentation
  |- Translation
  |- Depth estimation
  |- Vectorization
  |- Re-identification
- Representation Learning
- Pose Estimation
- Image Retrieval
- Visual Correspondence
- Character Recognition
- 3D Character Creation
- Robotics
- Speech Synthesis
- Adult Content Detection
- Survey
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;When it comes to the papers, each record has three or four fields depending on the existence of subcategories.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Subcategory&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;optional&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;category&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;does&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;not&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;have&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;subcategories&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;this&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;field&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;does&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;not&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;exist&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Paper&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;required&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;The&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;link&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;and&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;of&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;paper&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Conference&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;optional&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;The&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;abbreviated&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;form&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;of&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;conference&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;name&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;including&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;year&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Links&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;optional&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Webpages&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;describing&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;paper&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;aside&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;from&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;published&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;paper&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;e&lt;/span&gt;.&lt;span class="nv"&gt;g&lt;/span&gt;.&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Github&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;repository&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;or&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;specific&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;webpage&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;.&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Multiple&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;sources&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;are&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;OK&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;As for the projects, each record has the link and the name of the project. If the project is about the tech report and the webpage, the title is treated as the name. If the project is about the github repository, a combination of the username and the name of the repository corresponds to the name.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Present Challenges&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Diversity&lt;ul&gt;
&lt;li&gt;There are two aspects about the diversity: number of papers and uniqueness.&lt;ul&gt;
&lt;li&gt;Number of papers: I have noticed that the current version of AwesomeAnimeResearch lacks papers among several categories. Some categories include abundant papers, and others do not. I have to admit that the lack comes from my interests. Although several issue builders and contributers have mitigated the problem, there seems still be imbalanced with respect to the number of papers. Moreover, the categorization that I showed in the design section is not expected for researchers working on speech processing and natural language processing because the current categories lack papers related to the areas.&lt;/li&gt;
&lt;li&gt;Uniqueness: Papers among some categories would be overabundant because several pairs of the papers in one category mostly resemble each other. The truncation would be imperative to enable users to access to the desired paper faster.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Completeness&lt;ul&gt;
&lt;li&gt;A lot of dead links for the paper and blanks in the conference name exist. Especially as for the former problem, it significantly decreases the accessibility of users.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Future Plans&lt;/h2&gt;
&lt;p&gt;I will continue to add papers and projects to the repository via a search in reddit and google scholar. I also always accept issues and PR from others. Especially the latter leads to mitigating the problems of diversity. On the other hand, I am thinking about creating the script to search papers related to each category. This script would not only solve the problem of dead links and blanks but also enhance the objectiveness in searching the papers. If you have questions, corrections, or suggestions, I am willing to welcome and discuss them via Github Issue.&lt;/p&gt;</content><category term="cs"></category><category term="cs"></category></entry><entry><title>About Me</title><link href="/about.html" rel="alternate"></link><published>2022-06-19T00:00:00+09:00</published><updated>2023-03-31T00:00:00+09:00</updated><author><name>lento</name></author><id>tag:None,2022-06-19:/about.html</id><summary type="html">&lt;h2&gt;Personal Information&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Name: So Hasegawa&lt;/li&gt;
&lt;li&gt;Age: 29&lt;/li&gt;
&lt;li&gt;Mail: crosssceneofwindff |at| gmail |dot| com&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Publications and Conferences&lt;/h2&gt;
&lt;h3&gt;Peer reviewed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://openreview.net/forum?id=OJ8aSjCaMNK"&gt;Multi-Rate VAE: Train Once, Get the Full Rate-Distortion Curve&lt;/a&gt;&lt;br&gt;
  J. Bae, M. R. Zhang, M. Ruan, E. Wang, &lt;strong&gt;S. Hasegawa&lt;/strong&gt;, J. Ba, R. Grosse&lt;br&gt;
  In International Conference on Learning Representations (ICLR), 2023 …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;h2&gt;Personal Information&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Name: So Hasegawa&lt;/li&gt;
&lt;li&gt;Age: 29&lt;/li&gt;
&lt;li&gt;Mail: crosssceneofwindff |at| gmail |dot| com&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Publications and Conferences&lt;/h2&gt;
&lt;h3&gt;Peer reviewed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://openreview.net/forum?id=OJ8aSjCaMNK"&gt;Multi-Rate VAE: Train Once, Get the Full Rate-Distortion Curve&lt;/a&gt;&lt;br&gt;
  J. Bae, M. R. Zhang, M. Ruan, E. Wang, &lt;strong&gt;S. Hasegawa&lt;/strong&gt;, J. Ba, R. Grosse&lt;br&gt;
  In International Conference on Learning Representations (ICLR), 2023&lt;/li&gt;
&lt;li&gt;&lt;a href="https://openaccess.thecvf.com/content/WACV2023/html/Hasegawa_Improving_Predicate_Representation_in_Scene_Graph_Generation_by_Self-Supervised_Learning_WACV_2023_paper.html"&gt;Improving Predicate Representation in Scene Graph Generation by Self-Supervised Learning&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;S. Hasegawa&lt;/strong&gt;, M. Hiromoto, A. Nakagawa, Y. Umeda&lt;br&gt;
  In IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2023&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Non-peer reviewed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://onepetro.org/SPEADIP/proceedings-abstract/20ADIP/3-20ADIP/D031S080R004/452202"&gt;Facilitating the Identification of the Nannofossil Species in Cretaceous of Abu Dhabi Using Artificial Intelligence&lt;/a&gt;&lt;br&gt;
  H. Tamamura, M. Yamanaka, S. Chiyonobu, G. Yamada, &lt;strong&gt;S. Hasegawa&lt;/strong&gt;, Y. Totake, T. Nanjo&lt;br&gt;
  In Abu Dhabi International Petroleum Exhibition &amp;amp; Conference, 2020&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.jstage.jst.go.jp/article/jsapmeeting/2017.2/0/2017.2_848/_article/-char/ja/"&gt;Analysis of light absorption characteristics in very-thin single-crystalline silicon solar cells with photonic crystals&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;S. Hasegawa&lt;/strong&gt;, K. Ishizaki, Y. Tanaka, and S. Noda&lt;br&gt;
  In 78th Japan Society of Applied Physics (JSAP) Autumn Meeting, 2017&lt;/li&gt;
&lt;li&gt;&lt;a href="https://confit.atlas.jp/guide/event/jsap2016s/subject/22a-S621-3/advanced"&gt;Numerical analysis of μc-Si solar cells with photonic crystals formed on top surface -Introduction of asymmetric structure-&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;S. Hasegawa&lt;/strong&gt;, K. Ishizaki, Y. Tanaka, A. Motohira, Y. Kawamoto, M. De Zoysa, S. Fujita, and S. Noda&lt;br&gt;
  In 63th Japan Society of Applied Physics (JSAP) Spring Meeting, 2016&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Invited Lectures and Talks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.slideshare.net/SouHasegawa/generative-adversarial-networks-186237021"&gt;Generative Adversarial Networksの基礎と応用について (Basics and Applications of Generative Adversarial Network)&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;S. Hasegawa&lt;/strong&gt;&lt;br&gt;
  Invited lecture at Tohoku University, 2019&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.slideshare.net/SouHasegawa/ss-189697036"&gt;データに寄りそう着色の作法 (Basics of Line Art Colorization)&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;S. Hasegawa&lt;/strong&gt;&lt;br&gt;
  Talk at &lt;a href="https://connpass.com/event/149734/"&gt;創作＋機械学習LT会&lt;/a&gt;, 2019&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Education&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Apr 2016 ~ Mar 2018: MEng in Electronics at Kyoto University&lt;ul&gt;
&lt;li&gt;Thesis: Fabrication and Evaluation of Thin Single-Crystalline Silicon Solar Cells with Photonic Crystals&lt;/li&gt;
&lt;li&gt;Supervisor: Susumu Noda&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Apr 2012 ~ Mar 2016: BEng in Electrical and Electronic Engineering at Kyoto University&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Work Experience&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Oct 2022 ~ : machine learning researcher at Fujitsu Research of America&lt;ul&gt;
&lt;li&gt;My research is focused on AutoML&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Aug 2021 ~ Sep 2022: machine learning researcher at Fujitsu Research&lt;ul&gt;
&lt;li&gt;My research was focused on scene graph generation, self-supervised learning, and generative models&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sep 2019 - Jan 2020: research assistant at SYMBOL&lt;ul&gt;
&lt;li&gt;My work was focused on developing deep learning-based solutions to extract essential information from 3D data (point cloud, mesh, multi-view)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Apr 2018 ~ Jul 2021: software engineer at Fujitsu&lt;ul&gt;
&lt;li&gt;My work was focused on providing deep learning-based solutions with the customers and developing software products using speech processing and computer vision technologies&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Personal Projects&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Project name&lt;/th&gt;
&lt;th&gt;Descrption&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/SerialLain3170/adeleine"&gt;adeleine&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Deep learning-based implementations of line art colorization with hints and without hints. Userhintv2 model in the repository is used in &lt;a href="https://experiments.withgoogle.com/giga-manga"&gt;Giga Manga&lt;/a&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/SerialLain3170/senju"&gt;senju&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Several deep-learning based implementations pertaining to anime. The repository also includes GUI application consisting of Go server and Python modules connected via gRPC.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/SerialLain3170/accela"&gt;accela&lt;/a&gt; and &lt;a href="https://github.com/SerialLain3170/cyberia"&gt;cyberia&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Music digging tools. accela is implemented in TypeScript, and cyberia is done in Python.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="https://github.com/SerialLain3170/AwesomeAnimeResearch"&gt;AwesomeAnimeResearch&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;A massive collection of machine learning papers and projects related to anime&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;Skills&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Computer Science&lt;ul&gt;
&lt;li&gt;Machine Learning, Deep learning&lt;/li&gt;
&lt;li&gt;Signal Processing: Computer vision, Speech processing&lt;/li&gt;
&lt;li&gt;Low-level Programming: Emulators of NES, GB, CGB&lt;/li&gt;
&lt;li&gt;Programming Language: Python, Go, C&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Software Development&lt;ul&gt;
&lt;li&gt;Team development&lt;/li&gt;
&lt;li&gt;OS: Linux(Ubuntu, CentOS), MacOS, Windows&lt;/li&gt;
&lt;li&gt;Tools: Docker, Docker-compose, Git, Gitlab, Github, MySQL, PostgreSQL, MongoDB, Nodejs, gRPC, Nginx, RabbitMQ&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Language&lt;ul&gt;
&lt;li&gt;Japanese: native&lt;/li&gt;
&lt;li&gt;English: advanced (TOEFL: 96, IELTS: 7.0, GRE: V153/Q170/AW3.5)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Interests&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Programming (visit &lt;a href="https://github.com/SerialLain3170"&gt;Github&lt;/a&gt; and &lt;a href="https://medium.com/@crosssceneofwindff"&gt;Medium&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Visual arts: watching all kinds of arts, visiting art museums, and learning art history&lt;/li&gt;
&lt;li&gt;Books: science (computer science, biology, geology), art, history, finance (visit &lt;a href="https://bookmeter.com/users/1378090"&gt;Bookmeter&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Music: listening, playing the piano, composing (visit &lt;a href="https://soundcloud.com/lento-3"&gt;Soundcloud&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Travel and enjoy nature (visit &lt;a href="https://www.flickr.com/photos/197623303@N08/"&gt;flickr&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;</content><category term="about"></category><category term="about"></category></entry></feed>